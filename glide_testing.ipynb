{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "glide-testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/eliohead/glide-finetune-colab/blob/main/glide_testing.ipynb)"
      ],
      "metadata": {
        "id": "5z3ymiUOmpUB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5f4iNvdbjhS"
      },
      "outputs": [],
      "source": [
        "!pip install -q 'git+https://github.com/crowsonkb/glide-text2im'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import torch as th\n",
        "import torch.nn as nn\n",
        "\n",
        "from glide_text2im.clip.model_creation import create_clip_model\n",
        "from glide_text2im.download import load_checkpoint\n",
        "from glide_text2im.model_creation import (\n",
        "    create_model_and_diffusion,\n",
        "    model_and_diffusion_defaults,\n",
        "    model_and_diffusion_defaults_upsampler,\n",
        ")\n",
        "from glide_text2im.tokenizer.simple_tokenizer import SimpleTokenizer"
      ],
      "metadata": {
        "id": "t2Oe_yKqb2C6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Device setup\n",
        "# This notebook supports both CPU and GPU.\n",
        "# On CPU, generating one sample may take on the order of 20 minutes.\n",
        "# On a GPU, it should be under a minute.\n",
        "\n",
        "has_cuda = th.cuda.is_available()\n",
        "device = th.device('cpu' if not has_cuda else 'cuda')"
      ],
      "metadata": {
        "id": "XUX6IT8vb3pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sampling parameters\n",
        "prompt = \"A yellow flower\" #@param {type:\"string\"}\n",
        "batch_size =  2 #@param {type:\"number\"}\n",
        "guidance_scale =  8#@param {type:\"number\"}\n",
        "\n",
        "#@markdown `upsample_temp` Tune this parameter to control the sharpness of 256x256 images.\n",
        "# A value of 1.0 is sharper, but sometimes results in grainy artifacts.\n",
        "upsample_temp = 1.0\n",
        "\n",
        "base_timestep_respacing = '40' #@param {type:\"string\"}\n",
        "\n",
        "sr_timestep_respacing = 'fast27'"
      ],
      "metadata": {
        "id": "li4exw15b5Qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insert here your GLIDE finetuned model checkpoint"
      ],
      "metadata": {
        "id": "7uBVwYuIcX85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create base model.\n",
        "glide_path = '/content/drive/MyDrive/glide-ft-87x799.pt' #@param {type:\"string\"}\n",
        "import os\n",
        "options = model_and_diffusion_defaults()\n",
        "options['use_fp16'] = has_cuda\n",
        "options['timestep_respacing'] = base_timestep_respacing # use 100 diffusion steps for fast sampling\n",
        "model, diffusion = create_model_and_diffusion(**options)\n",
        "\n",
        "if len(glide_path) > 0:\n",
        "    assert os.path.exists(\n",
        "        glide_path\n",
        "    ), f\"Failed to resume from {glide_path}, file does not exist.\"\n",
        "    weights = th.load(glide_path, map_location=\"cpu\")\n",
        "    model, diffusion = create_model_and_diffusion(**options)\n",
        "    model.load_state_dict(weights)\n",
        "    print(f\"Resumed from {glide_path} successfully.\")\n",
        "else:\n",
        "    model, diffusion = create_model_and_diffusion(**options)\n",
        "    model.load_state_dict(load_checkpoint(\"base\", device))\n",
        "model.eval()\n",
        "if has_cuda:\n",
        "    model.convert_to_fp16()\n",
        "model.to(device)\n",
        "print('total base parameters', sum(x.numel() for x in model.parameters()))"
      ],
      "metadata": {
        "id": "juvRtS0RcUvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insert here upsampler checkpoint"
      ],
      "metadata": {
        "id": "LRb7l3PachwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Create upsampler model.\n",
        "sr_glide_path = '/content/drive/MyDrive/glide-ft-121x1198.pt' #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "options_up = model_and_diffusion_defaults_upsampler()\n",
        "options_up['use_fp16'] = has_cuda\n",
        "options_up['timestep_respacing'] = sr_timestep_respacing # use 27 diffusion steps for very fast sampling\n",
        "\n",
        "if len(sr_glide_path) > 0:\n",
        "    assert os.path.exists(\n",
        "        sr_glide_path\n",
        "    ), f\"Failed to resume from {sr_glide_path}, file does not exist.\"\n",
        "    weights = th.load(sr_glide_path, map_location=\"cpu\")\n",
        "    model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
        "    model_up.load_state_dict(weights)\n",
        "    print(f\"Resumed from {sr_glide_path} successfully.\")\n",
        "else:\n",
        "    model_up, diffusion_up = create_model_and_diffusion(**options)\n",
        "    model_up.load_state_dict(load_checkpoint(\"upsample\", device))\n",
        "\n",
        "if has_cuda:\n",
        "    model_up.convert_to_fp16()\n",
        "model_up.to(device)\n",
        "print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))"
      ],
      "metadata": {
        "id": "8DF-caT3cehS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Util\n",
        "def show_images(batch: th.Tensor):\n",
        "    \"\"\" Display a batch of images inline. \"\"\"\n",
        "    scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
        "    reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
        "    display(Image.fromarray(reshaped.numpy()))"
      ],
      "metadata": {
        "id": "zKvvWy4CcryJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Base model sampling\n",
        "##############################\n",
        "# Sample from the base model #\n",
        "##############################\n",
        "# Create the text tokens to feed to the model.\n",
        "\n",
        "tokens = model.tokenizer.encode(prompt)\n",
        "tokens, mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options[\"text_ctx\"]\n",
        ")\n",
        "uncond_tokens, uncond_mask = model.tokenizer.padded_tokens_and_mask(\n",
        "    [], options[\"text_ctx\"]\n",
        ")\n",
        "model_kwargs = dict(\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size + [uncond_tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size + [uncond_mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "def cfg_model_fn(x_t, ts, **kwargs):\n",
        "    half = x_t[: len(x_t) // 2]\n",
        "    combined = th.cat([half, half], dim=0)\n",
        "    model_out = model(combined, ts, **kwargs)\n",
        "    eps, rest = model_out[:, :3], model_out[:, 3:]\n",
        "    cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim=0)\n",
        "    half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n",
        "    eps = th.cat([half_eps, half_eps], dim=0)\n",
        "    return th.cat([eps, rest], dim=1)\n",
        "# Sample from the base model.\n",
        "\n",
        "\n",
        "full_batch_size = batch_size * 2\n",
        "model.del_cache()\n",
        "samples = diffusion.plms_sample_loop(\n",
        "    cfg_model_fn,\n",
        "    (full_batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(samples)"
      ],
      "metadata": {
        "id": "nJAM-h6ectr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upsampling 4x\n",
        "\n",
        "##############################\n",
        "# Upsample the 64x64 samples #\n",
        "##############################\n",
        "\n",
        "tokens = model_up.tokenizer.encode(prompt)\n",
        "tokens, mask = model_up.tokenizer.padded_tokens_and_mask(\n",
        "    tokens, options_up['text_ctx']\n",
        ")\n",
        "\n",
        "# Create the model conditioning dict.\n",
        "model_kwargs = dict(\n",
        "    # Low-res image to upsample.\n",
        "    low_res=((samples+1)*127.5).round()/127.5 - 1,\n",
        "\n",
        "    # Text tokens\n",
        "    tokens=th.tensor(\n",
        "        [tokens] * batch_size, device=device\n",
        "    ),\n",
        "    mask=th.tensor(\n",
        "        [mask] * batch_size,\n",
        "        dtype=th.bool,\n",
        "        device=device,\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Sample from the base model.\n",
        "model_up.del_cache()\n",
        "up_shape = (batch_size, 3, options_up[\"image_size\"], options_up[\"image_size\"])\n",
        "up_samples = diffusion_up.plms_sample_loop(\n",
        "    model_up,\n",
        "    up_shape,\n",
        "    noise=th.randn(up_shape, device=device) * upsample_temp,\n",
        "    device=device,\n",
        "    clip_denoised=True,\n",
        "    progress=True,\n",
        "    model_kwargs=model_kwargs,\n",
        "    cond_fn=None,\n",
        ")[:batch_size]\n",
        "model_up.del_cache()\n",
        "\n",
        "# Show the output\n",
        "show_images(up_samples)"
      ],
      "metadata": {
        "id": "nrcTB0vZcxXR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}